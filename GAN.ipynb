{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\n# Sample data for demonstration\ndata = {\n    'Feature1': np.random.rand(100),\n    'Feature2': np.random.rand(100),\n    'Target': np.random.randint(0, 2, 100)\n}\n\n# Convert to DataFrame\ndf = pd.DataFrame(data)\n\n# Display first few rows\ndf.head()\n\n# Data preprocessing\nscaler = StandardScaler()\ndf[['Feature1', 'Feature2']] = scaler.fit_transform(df[['Feature1', 'Feature2']])\n\n# Display processed data\ndf.head()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorflow.keras import layers\nimport numpy as np\n\n# Define the generator model\ndef build_generator():\n    model = tf.keras.Sequential([\n        layers.Dense(128, activation='relu', input_dim=100),\n        layers.Dense(2, activation='tanh')\n    ])\n    return model\n\n# Define the discriminator model\ndef build_discriminator():\n    model = tf.keras.Sequential([\n        layers.Dense(128, activation='relu', input_dim=2),\n        layers.Dense(1, activation='sigmoid')\n    ])\n    return model\n\n# Define the GAN model\ndef build_gan(generator, discriminator):\n    model = tf.keras.Sequential([generator, discriminator])\n    return model\n\n# Compile models\ngenerator = build_generator()\ndiscriminator = build_discriminator()\ngan = build_gan(generator, discriminator)\n\ndiscriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\ngan.compile(optimizer='adam', loss='binary_crossentropy')\n\n# GAN training function\ndef train_gan(epochs=10000, batch_size=64):\n    for epoch in range(epochs):\n        # Generate fake data\n        noise = np.random.randn(batch_size, 100)\n        generated_data = generator.predict(noise)\n        \n        # Combine real and fake data\n        real_data = df[['Feature1', 'Feature2']].sample(batch_size).values\n        combined_data = np.concatenate([real_data, generated_data], axis=0)\n        labels = np.array([1] * batch_size + [0] * batch_size)\n        \n        # Train discriminator\n        d_loss = discriminator.train_on_batch(combined_data, labels)\n        \n        # Train generator\n        noise = np.random.randn(batch_size, 100)\n        g_loss = gan.train_on_batch(noise, np.array([1] * batch_size))\n        \n        if epoch % 1000 == 0:\n            print(f'Epoch {epoch}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}')\n\ntrain_gan()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Define the conditional generator model\ndef build_conditional_generator():\n    model = tf.keras.Sequential([\n        layers.Dense(128, activation='relu', input_dim=110),\n        layers.Dense(2, activation='tanh')\n    ])\n    return model\n\n# Define the conditional discriminator model\ndef build_conditional_discriminator():\n    model = tf.keras.Sequential([\n        layers.Dense(128, activation='relu', input_dim=12),\n        layers.Dense(1, activation='sigmoid')\n    ])\n    return model\n\n# Define the Conditional GAN model\ndef build_conditional_gan(generator, discriminator):\n    model = tf.keras.Sequential([generator, discriminator])\n    return model\n\n# Compile models\nc_generator = build_conditional_generator()\nc_discriminator = build_conditional_discriminator()\nc_gan = build_conditional_gan(c_generator, c_discriminator)\n\nc_discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nc_gan.compile(optimizer='adam', loss='binary_crossentropy')\n\n# Conditional GAN training function\ndef train_conditional_gan(epochs=10000, batch_size=64):\n    for epoch in range(epochs):\n        # Generate fake data with labels\n        noise = np.random.randn(batch_size, 100)\n        labels = np.random.randint(0, 2, batch_size)\n        conditional_input = np.concatenate([noise, labels.reshape(-1, 1)], axis=1)\n        generated_data = c_generator.predict(conditional_input)\n        \n        # Combine real and fake data\n        real_data = np.concatenate([df[['Feature1', 'Feature2']], np.random.randint(0, 2, (df.shape[0], 1))], axis=1)\n        combined_data = np.concatenate([real_data, np.concatenate([generated_data, labels.reshape(-1, 1)], axis=1)], axis=0)\n        real_labels = np.array([1] * batch_size + [0] * batch_size)\n        \n        # Train discriminator\n        c_d_loss = c_discriminator.train_on_batch(combined_data, real_labels)\n        \n        # Train generator\n        noise = np.random.randn(batch_size, 100)\n        c_g_loss = c_gan.train_on_batch(np.concatenate([noise, np.random.randint(0, 2, (batch_size, 1))], axis=1), np.array([1] * batch_size))\n        \n        if epoch % 1000 == 0:\n            print(f'Epoch {epoch}, Discriminator Loss: {c_d_loss[0]}, Generator Loss: {c_g_loss}')\n\ntrain_conditional_gan()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}